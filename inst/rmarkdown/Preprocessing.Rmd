---
author: "Admin"
date: "24 4 2019"
output:
  html_document:
    df_print: paged
    includes:
      after_body: footer.html
runtime: shiny
params:
  data: ""
  data_to_predict: NULL
  title: ""
  target: ""
  type: ""
---

<style type="text/css">
h1.title, h4.date, h4.abstract, p.abstract{
  text-align: center;
}
h1.title{
  margin-top: 30px;
}
h4.abstract{
  margin-top: 50px;
}
.outer{
width: 100%;
}
.scrolltable { margin-top: 20px; height: 450px; overflow: auto; }
.scrolltable table { border-collapse: collapse; }
.scrolltable tr:nth-child(even) { background: #EEE; }
.expand tr:nth-child(even) { background: #EEE; }
#expandButton{
  cursor: pointer;
}
#pipeline{
  background-color: #EEE;
  font-size: 110%;
  padding-bottom: 0px;
  padding-top: 0px;
  border-color: transparent;
  width: fit-content;
}
#section-generations{
  text-align: center;
}
#section-predictions div{
  text-align: center;
 }
#section-explenation{
  text-align: center;
 }
#predictions div{
  max-height: 300px;
  margin-top: 15px;
  padding: 0px !important;
}
#section-predictions div table thead tr th{
  text-align: center !important;
}
#section-predictions div table tbody tr td{
  text-align: center !important;
}
</style>

<script>
var isExpanded = false
function expand() {
  isExpanded ? document.getElementById('section-scrolltable').setAttribute("class", "scrolltable") : document.getElementById('section-scrolltable').setAttribute("class", "expand")
  isExpanded = !isExpanded
}
</script>

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
require("summarytools")
require("tpotr")
require("mlr")
require("stringr")
require("knitr")
require("iml")
require("lime")
require("ggplot2")
require("kableExtra")
require("magrittr")
```

<!-- HEADER SECTION --> 
<div class="container outer">

<div class="row">

<div class="col-sm">

<h1 class="title">`r paste('Automatic report for the dataset:',params$title)`</h1>
<h4 class="date">`r Sys.Date()`</h4>
<h4 class="abstract">Abstract</h4>
<p class="abstract"> This is a report analysing the dataset `r params$title`. </p>
<hr>

</div>

</div>

</div>

<!-- FIRST SECTION --> 

<div class="container outer">

<div class="row">

<div class="col-sm">

<h3>Brief description of the data set</h3>
<<<<<<< HEAD
<p> To confirm that the dataset was loaded correctly, a small summary of the data is given. The dataset has `r ncol(data)` features (columns) and `r nrow(data)` observations (rows). The feature of interest, the target column, is "`r colnames(data)[length(data)]`" and has `r length(levels(data[,length(data)]))` classes (`r levels(data[,length(data)])`). Therefore, it fits to a classification problem and can be used in this version of the Automatic Statistician. The table below goes across all the dataset's features and shall give an descriptive overview of each feature. It provides the following information: <strong>No:</strong> The number of the feature indicating the order in which it appears in the dataset. <strong>Attribute:</strong> The name of the feature and its class. <strong>Stats/Values:</strong> An insight into the feature's values. <strong>Freqs: </strong> The frequency, proportions or number of distinct values. <strong>Graph:</strong> A histogram or barplot of the feature's values. <strong> Valid/Missing:</strong> The number and proportion of valid and missing values in the feature. You can <a id = "expandButton" onclick="expand()">expand/collapse</a> the table.</p><br>
=======
<p> To confirm that the dataset was loaded correctly, a small summary of the data is given. The dataset has `r ncol(data)` columns and `r nrow(data)` rows. The target column is "`r target`" and has `r length(levels(data[,length(data)]))` classes (`r levels(data[,length(data)])`). Therefore, it fits to a classification problem and can be used in this version of the automatic statistician. The table below goes across all the dataset's features. It provides information about the attribute's class, univariate statistics, attribute values, value frequency and value validity. You can <a id = "expandButton" onclick="expand()">expand/collapse</a> the table.</p><br>
>>>>>>> f7a13056c57226491fbc4d0e23190d0dcf0ae61f

<div id="scrolltable" class="scrolltable">

```{r results='asis', echo=FALSE}
data <- data
print(dfSummary(data, plain.ascii = FALSE, style = "grid", graph.magnif = 0.8, headings = FALSE, tmp.img.dir = "/tmp"))
#dfSummary(data, plain.ascii = FALSE, style = "grid")
```

</div>

</div>

</div>

</div>

<!-- SECOND SECTION --> 

<div class="container outer">

<div class="row">

<div class="col-sm">

<h3>Fitting a machine learning pipeline</h3>

```{r echo=FALSE, include=FALSE}
learner <- makeLearner(cl = "classif.tpot", predict.type = "prob", 
                       population_size = 10, generations = 15, 
                       verbosity = 2)
if(type=="classif"){
  task <- makeClassifTask(data = params$data, target = params$target)
} else{
  task <- makeRegrTask(data = params$data, target = params$target)
}
mod = NULL
pred = NULL
again = TRUE
while(again == TRUE){
  result = try({
    mod = train(learner, task)
    #pred = predict(obj = mod, newdata = test)
  }, silent = TRUE)
  if (inherits(result, "try-error")){
    again = TRUE
  } else {
    again = FALSE
  }
}
pipeline <- getPipeline(mod)
generations <- getGenerations(mod)
```

<p>The Automated Statistician has found a TPOT machine learning pipeline, that can predict the target variable "`r colnames(data)[length(data)]`" in the dataset "`r params$title`". The best machine learning pipeline is:</p>

<pre id="pipeline">
<code>
`r pipeline`
</code>
</pre>

<p>
To find the best learning pipeline, the Automated Statistician iterated over a total of `r length(generations)` generations. The best pipeline has an accurancy of `r max(generations)` for the input training data. Below is a plot which shows how the accuracy developed over the generations.
</p>

<div id="generations">
```{r echo=FALSE}
plot(generations, type="b", xlab="Generations", ylab="CV score", xaxt="n")
axis(1, at = seq(1, 15, by = 1), las=2)
```
</div>

<div id="predictions"> 

`r if(nrow(params$data_to_predict)){"For the provided test data the pipeline predicted the missing target feature values:"}`
```{r echo=FALSE}
if(nrow(params$data_to_predict) > 0){
  test <- params$data_to_predict[,1:ncol(params$data_to_predict)-1]
  prediction <- cbind("Prediction" = predict(obj = mod, newdata = test)$data$response, test)
  write.csv2(prediction, "./prediction.csv")
  readLines("./prediction.csv") %>% 
  paste0(collapse="\n") %>% 
  openssl::base64_encode() -> encoded
}
```
```{r echo=FALSE}
if(nrow(params$data_to_predict) > 0){
  kable(prediction) %>% kable_styling(fixed_thead = T) %>% scroll_box(width = "100%")
  #print(performance(pred = prediction, measures=list(acc)))
}
```

</div>

`r if(nrow(params$data_to_predict)){"<a download='prediction.csv' href='r sprintf('data:text/csv;base64,%s', encoded)'>Download this data as .csv</a>"}`

</div>

</div>

</div>

<!-- THIRD SECTION --> 

<div class="container outer">

<div class="row">

<div class="col-sm">

<h3>Model explanation</h3>
<p> To explain the model generated by tpot different model-agnostic methods are used:</p>

```{r include=FALSE}
predictor <- Predictor$new(mod, data=params$data, y = params$target)
imp <- FeatureImp$new(predictor, loss = "ce", compare = "difference")
imp.df <- imp$results
imp.df[,"cum_importance"] <- cumsum(imp.df$importance)
imp.sum <- sum(imp.df$importance)
imp.cum <- imp.df[,"cum_importance"]
imp.df[,"cum_importance"] <- sapply(imp.cum, function(x){
  x / imp.sum
})
min <- min(which(imp.df[,"cum_importance"] > 0.8))
imp.features <- imp.df[1:min,"feature"]
imp.features
```

<h4>Feature Importance</h4>
<p>The importance of a feature is measured by calculating the increase in the model’s prediction error after permuting the feature. A feature is “important” if shuffling its values increases the model error, because in this case the model relied on the feature for the prediction.</p>

<p>From the <b>`r length(data) - 1`</b> features of the data set the following <b>`r length(imp.features)`</b> are identified as the most important features that explain at least <b>80%</b> of the prediction error: <b>`r paste(imp.features, sep = ", ")`</b>.</p>

<p>The following plot shows the importance of each feature. The ratio of classification error is calculated as follows: Increase in classification error through permutation divided by the original classification error. The dot is the median and the bar describes the range of the classification error ratio.</p>

<div id="explenation">
```{r echo=FALSE}
plot(imp) + labs(x = "Feature Importance (Classification Error as Loss)", y = "Feature") + theme_bw()
```
</div>

<h4>Accumulated Local Effects</h4>
<p>Accumulated local effects (ALE) describe how features influence the prediction of a machine learning model on average.</p>

<p>For the given classification problem the most important feature according to the feature importance analysis, which is <b>`r paste(imp.features[1], sep = ", ")`</b>, is analysed by the ALE for the target <b>`r target`</b>.</p>

<div id="explenation">
```{r echo=FALSE}
mostimp <- imp$results[1,1]
ale <- FeatureEffect$new(predictor, feature = mostimp)
ale$plot() + theme_bw()
```
</div>

<h4>Lime</h4>
<p>Local surrogate models like LIME are interpretable models that are used to explain individual predictions of black box machine learning models.</p>

<p>To explain the inner working of the found model, randomely 5 observations are selected for each class and their belonging to each class is explained with LIME.</p>

<p>In the following plots for each class the 5 selected observations are eplained by LIME the coulour represents the feature weight and gives an indication, which features influence the prediction.</p>

<div id="explenation">
```{r echo=FALSE}
explainer <- lime(params$data, mod)
levels <- levels(params$data[,params$target])

for(level in levels){
  tempdata <-params$data[params$data[,params$target] == level,]
  nrow <- nrow(tempdata)
  sample <- sample.int(nrow, size = 5, replace = FALSE)
  explanation <- explain(tempdata[sample,], explainer, n_labels = 1, n_features = 5)
  print(plot_explanations(explanation))
}
```
</div>

</div>

</div>

</div>

